{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the training Data\n",
    "train_pd = pd.read_csv('data/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived       891\n",
       "Pclass         891\n",
       "Name           891\n",
       "Sex            891\n",
       "Age            714\n",
       "SibSp          891\n",
       "Parch          891\n",
       "Ticket         891\n",
       "Fare           891\n",
       "Cabin          204\n",
       "Embarked       889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we summaize some Information about the data set\n",
    "train_pd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we summaize some Information about the data set\n",
    "train_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean age:  29.6991176471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId    888\n",
       "Survived       888\n",
       "Pclass         888\n",
       "Name           888\n",
       "Sex            888\n",
       "Age            888\n",
       "SibSp          888\n",
       "Parch          888\n",
       "Ticket         888\n",
       "Fare           888\n",
       "Cabin          202\n",
       "Embarked       886\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because we were missing values for the age, we now replace the na values with the mean age\n",
    "\n",
    "train_pd['Age'].describe()\n",
    "mean_age = train_pd['Age'].describe()[1]\n",
    "\n",
    "print 'mean age: ', mean_age\n",
    "\n",
    "train_pd['Age'] = train_pd['Age'].fillna(mean_age)\n",
    "\n",
    "# We also discard any values for the Fair that appear as outliers, in this case, the >= $500 ticket price\n",
    "train_pd = train_pd[ train_pd['Fare'] < 500.0]\n",
    "\n",
    "# Now we want to convert the gender Category into a numerical label\n",
    "# This function will be applied to the data frame\n",
    "def label_cat(x):\n",
    "    if x=='male':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "train_pd['Sex'] = train_pd.apply(lambda x: label_cat(x['Sex']), axis=1)\n",
    "\n",
    "train_pd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>888.000000</td>\n",
       "      <td>888.000000</td>\n",
       "      <td>888.000000</td>\n",
       "      <td>888.000000</td>\n",
       "      <td>888.000000</td>\n",
       "      <td>888.000000</td>\n",
       "      <td>888.000000</td>\n",
       "      <td>888.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445.618243</td>\n",
       "      <td>0.381757</td>\n",
       "      <td>2.313063</td>\n",
       "      <td>0.647523</td>\n",
       "      <td>29.680083</td>\n",
       "      <td>0.524775</td>\n",
       "      <td>0.381757</td>\n",
       "      <td>30.582164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.405474</td>\n",
       "      <td>0.486091</td>\n",
       "      <td>0.834007</td>\n",
       "      <td>0.478011</td>\n",
       "      <td>13.019819</td>\n",
       "      <td>1.104186</td>\n",
       "      <td>0.806949</td>\n",
       "      <td>41.176366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>667.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.771850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>263.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Sex         Age  \\\n",
       "count   888.000000  888.000000  888.000000  888.000000  888.000000   \n",
       "mean    445.618243    0.381757    2.313063    0.647523   29.680083   \n",
       "std     257.405474    0.486091    0.834007    0.478011   13.019819   \n",
       "min       1.000000    0.000000    1.000000    0.000000    0.420000   \n",
       "25%     222.750000    0.000000    2.000000    0.000000   22.000000   \n",
       "50%     445.500000    0.000000    3.000000    1.000000   29.699118   \n",
       "75%     667.250000    1.000000    3.000000    1.000000   35.000000   \n",
       "max     891.000000    1.000000    3.000000    1.000000   80.000000   \n",
       "\n",
       "            SibSp       Parch        Fare  \n",
       "count  888.000000  888.000000  888.000000  \n",
       "mean     0.524775    0.381757   30.582164  \n",
       "std      1.104186    0.806949   41.176366  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    7.895800  \n",
       "50%      0.000000    0.000000   14.454200  \n",
       "75%      1.000000    0.000000   30.771850  \n",
       "max      8.000000    6.000000  263.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we check to see that we dropped the outliers\n",
    "\n",
    "train_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age     Fare\n",
       "0         0       3    1  22.0   7.2500\n",
       "1         1       1    0  38.0  71.2833\n",
       "2         1       3    0  26.0   7.9250\n",
       "3         1       1    0  35.0  53.1000\n",
       "4         0       3    1  35.0   8.0500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now group the data set according the the ticket class\n",
    "subset_df = train_pd[['Survived','Pclass','Sex','Age','Fare']]\n",
    "\n",
    "# Now we examine how Survival and Ticket class are related\n",
    "sns.pairplot(subset_df,hue='Survived',vars=[\"Fare\", \"Pclass\",\"Age\",\"Sex\"]);\n",
    "plt.show()\n",
    "\n",
    "subset_df.hist()\n",
    "plt.show()\n",
    "\n",
    "# Now lets look at our data set\n",
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows:  888\n",
      "split index:  621\n",
      "size of train :  621\n",
      "size of split :  267\n",
      "[ 0.752       0.78225806  0.78225806  0.81451613  0.75806452]\n",
      "[ 0.76        0.7983871   0.80645161  0.82258065  0.77419355]\n",
      "[ 0.728       0.80645161  0.65322581  0.71774194  0.75806452]\n",
      "[ 0.832       0.84677419  0.78225806  0.7983871   0.79032258]\n",
      "[ 0.744       0.7983871   0.78225806  0.81451613  0.78225806]\n",
      "\n",
      "Normalized Confusion Matrix\n",
      "\n",
      "[[ 0.78616352  0.31481481]\n",
      " [ 0.18238994  0.73148148]]\n",
      "[[ 0.82389937  0.25925926]\n",
      " [ 0.19496855  0.71296296]]\n",
      "[[ 0.1509434   1.25      ]\n",
      " [ 0.05031447  0.92592593]]\n",
      "[[ 0.91823899  0.12037037]\n",
      " [ 0.18867925  0.72222222]]\n",
      "[[ 0.82389937  0.25925926]\n",
      " [ 0.16981132  0.75      ]]\n"
     ]
    }
   ],
   "source": [
    "# Now that we have explored the data a bit, it's time to train a model and make some predictions\n",
    "# Models that we will consider: Naive Bayes, Random Forests, SVM \n",
    "# A. We will weigh the model predictions according to their confusion matrix \n",
    "# B. We will use K-fold cross validation to check accuracy of our models\n",
    "# C. We will take our classifiers and feed it into a another set of models (NB, RF, SVM) and see if we do better (Stacking)\n",
    "\n",
    "# The Features that we will use to train the predictive models will be:\n",
    "# 1. Pclass\n",
    "# 2. Sex\n",
    "# 3. Their Age\n",
    "# 4. Fare Paid\n",
    "\n",
    "# Let us take a subset of the data to train upon now:\n",
    "split_frac = 0.6\n",
    "total_indx = len(subset_np)\n",
    "split_indx = int(0.7*total_indx)\n",
    "\n",
    "print 'total rows: ', total_indx\n",
    "print 'split index: ', split_indx\n",
    "\n",
    "shuffle_df = shuffle(subset_np)\n",
    "train_np = shuffle_df[0:split_indx]\n",
    "test_np  = shuffle_df[split_indx:total_indx]\n",
    "\n",
    "print 'size of train : ', len(train_df)\n",
    "print 'size of split : ', len(test_df)\n",
    "\n",
    "\n",
    "# First we extract the labels of the data\n",
    "#train_np = train_df.values\n",
    "#test_np = test_df.values\n",
    "\n",
    "# Extract the Survival labels from the subsets\n",
    "train_labels = np.asarray([train_np[k][0] for k in range(len(train_np))])\n",
    "\n",
    "# Extract the feature matrix for all of the entries\n",
    "train_feature_matrix = np.asarray([train_np[k][1:] for k in range(len(train_np))])\n",
    "\n",
    "\n",
    "# Now we extract the tests labels and feature matrix\n",
    "test_labels = np.asarray([test_np[k][0] for k in range(len(test_np))])\n",
    "test_feature_matrix = np.asarray([test_np[k][1:] for k in range(len(test_np))])\n",
    "\n",
    "\n",
    "# Here we define all of the models that we use\n",
    "gnb = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "svc = LinearSVC(C=1.0)\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "adab = AdaBoostClassifier()\n",
    "\n",
    "\n",
    "#GaussianNB Fitting Procedure\n",
    "gnb.fit(train_feature_matrix,train_labels)\n",
    "lr.fit(train_feature_matrix,train_labels)\n",
    "svc.fit(train_feature_matrix,train_labels)\n",
    "rfc.fit(train_feature_matrix,train_labels)\n",
    "adab.fit(train_feature_matrix,train_labels)\n",
    "\n",
    "scores_gnb = cross_val_score(gnb, train_feature_matrix, train_labels, cv=5)\n",
    "scores_lr = cross_val_score(lr, train_feature_matrix,  train_labels, cv=5)\n",
    "scores_svc = cross_val_score(svc, train_feature_matrix,  train_labels, cv=5)\n",
    "scores_rfc = cross_val_score(rfc, train_feature_matrix,  train_labels, cv=5)\n",
    "scores_adab = cross_val_score(adab, train_feature_matrix, train_labels, cv=5)\n",
    "\n",
    "print scores_gnb\n",
    "print scores_lr\n",
    "print scores_svc\n",
    "print scores_rfc\n",
    "print scores_adab\n",
    "\n",
    "\n",
    "y_pred_gnb = gnb.predict(test_feature_matrix)\n",
    "y_pred_lr = lr.predict(test_feature_matrix)\n",
    "y_pred_svc = svc.predict(test_feature_matrix)\n",
    "y_pred_rfc = rfc.predict(test_feature_matrix)\n",
    "y_pred_adab = adab.predict(test_feature_matrix)\n",
    "\n",
    "# Now we make predictions on the test data set using all of the different models\n",
    "cm_gnb = confusion_matrix(test_labels, y_pred_gnb)\n",
    "cm_lr = confusion_matrix(test_labels, y_pred_lr)\n",
    "cm_svc =  confusion_matrix(test_labels, y_pred_svc)\n",
    "cm_rfc = confusion_matrix(test_labels, y_pred_rfc)\n",
    "cm_adab = confusion_matrix(test_labels, y_pred_adab)\n",
    "\n",
    "cm_gnb =  cm_gnb/cm_gnb.astype(np.float).sum(axis=1)\n",
    "cm_lr = cm_lr/cm_lr.astype(np.float).sum(axis=1)\n",
    "cm_svc = cm_svc/cm_svc.astype(np.float).sum(axis=1)\n",
    "cm_rfc = cm_rfc/cm_rfc.astype(np.float).sum(axis=1)\n",
    "cm_adab = cm_adab/cm_adab.astype(np.float).sum(axis=1)\n",
    "\n",
    "print ''\n",
    "print 'Normalized Confusion Matrix'\n",
    "print ''\n",
    "print cm_gnb\n",
    "print cm_lr\n",
    "print cm_svc\n",
    "print cm_rfc\n",
    "print cm_adab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we can experiment in the way that we combine all the prediction from the models\n",
    "\n",
    "def bayes_average(feature_matrix,model_array,cm_array):\n",
    "    \n",
    "    # Every row corresponds to all of the predctions of the models\n",
    "    y_pred_matrix = np.asarray([model.predict(feature_matrix) for model in model_array ]) \n",
    "    \n",
    "    y = []\n",
    "    \n",
    "    # Now for every model, we combine the predictions using the confusion matrix\n",
    "    # model_indx\n",
    "    # pred_indx\n",
    "    for pred_indx in range(0,len(y_pred_matrix[0])):\n",
    "        \n",
    "        prob_fake_cond_results = 0.0\n",
    "        prob_true_cond_results = 0.0\n",
    "         \n",
    "        for model_indx in range(0,len(model_array)):\n",
    "            \n",
    "            if y_pred_matrix[model_indx][pred_indx]==0:\n",
    "                cond_prob_result_given_false_k = cm_array[model_indx][0,1] # Wrong Classifications\n",
    "                cond_prob_result_given_true_k  = cm_array[model_indx][0,0] # Correct Classifications\n",
    "            else:\n",
    "                cond_prob_result_given_false_k = cm_array[model_indx][1,1] # Correct Classification\n",
    "                cond_prob_result_given_true_k  = cm_array[model_indx][1,0] # Wrong Classifications\n",
    "            \n",
    "            prob_fake_cond_results = prob_fake_cond_results+cond_prob_result_given_false_k\n",
    "            prob_true_cond_results = prob_true_cond_results+cond_prob_result_given_true_k\n",
    "                \n",
    "        \n",
    "        Normalization = prob_fake_cond_results+prob_true_cond_results\n",
    "        \n",
    "        prob_fake_cond_results = prob_fake_cond_results/Normalization\n",
    "        prob_true_cond_results = prob_true_cond_results/Normalization\n",
    "        \n",
    "        # The Final Prediction:\n",
    "        if prob_fake_cond_results >= prob_true_cond_results:\n",
    "            yk = 1.0\n",
    "        else:\n",
    "            yk = 0.0\n",
    "            \n",
    "        y.extend([yk])\n",
    "        \n",
    "    # Convert to Numy array \n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.80503145  0.28703704]\n",
      " [ 0.13836478  0.7962963 ]]\n"
     ]
    }
   ],
   "source": [
    "model_array = [gnb,lr,svc,rfc,adab]\n",
    "cm_array =[cm_gnb,cm_lr,cm_svc,cm_rfc,cm_adab]\n",
    "#bayes_average(test_feature_matrix,model_array,cm_array)\n",
    "\n",
    "y_pred_bayes = bayes_average(test_feature_matrix,model_array,cm_array)\n",
    "\n",
    "cm_bayes = confusion_matrix(test_labels, y_pred_bayes)\n",
    "cm_bayes = cm_bayes/cm_bayes.astype(np.float).sum(axis=1)\n",
    "\n",
    "print cm_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80149812734082393"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets compute the accuracy of this Bayesian combination of the models\n",
    "accuracy_score(test_labels, y_pred_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Now we read in the prediction data set and output our predictions as required.\n",
    "# We must fill in missing values, and process the data.\n",
    "# \"You should submit a csv file with exactly 418 entries plus a header row.\"\n",
    "# \"Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.\"\n",
    "pred_df = pd.read_csv('data/test.csv')\n",
    "pred_df['Fare'] = pred_df['Fare'].fillna(pred_df[\"Fare\"].describe()[1])\n",
    "pred_df['Age'] = pred_df['Age'].fillna(pred_df[\"Age\"].describe()[1])\n",
    "pred_df['Sex'] = pred_df.apply(lambda x: label_cat(x['Sex']), axis=1)\n",
    "##pred_df.head()\n",
    "\n",
    "# Now we extract the features\n",
    "feature_df = pred_df[['Pclass','Sex','Age','Fare']]\n",
    "pass_df = pred_df[['PassengerId']]\n",
    "\n",
    "#feature_df.head().describe()\n",
    "pred_np = np.asarray(feature_df)\n",
    "pass_np = np.asarray(pass_df)\n",
    "\n",
    "pred_feature_matrix = np.asarray([pred_np[k][:] for k in range(len(pred_np))])\n",
    "\n",
    "# Now that we have loaded the features, we make predictions\n",
    "y_pred = bayes_average(pred_feature_matrix,model_array,cm_array)\n",
    "\n",
    "y_pred = rfc.predict(pred_feature_matrix)\n",
    "\n",
    "\n",
    "with open('kaggle_predictions.csv', \"wb\") as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow(['PassengerId','Survived'])\n",
    "        \n",
    "        for k in range(0,len(pass_df)):\n",
    "            #writer.writerow(line)\n",
    "            writer.writerow([int(pass_np[k]), int(y_pred[k])])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
